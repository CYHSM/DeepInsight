{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pn9vUyWfZTX6",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "# **Introduction to DeepInsight - Decoding position from two-photon calcium recordings**\n",
    "---\n",
    "\n",
    "This notebook stands as an example of how to use DeepInsight on calcium data and can be used as a guide on how to adapt it to your own datasets. All methods are stored in the deepinsight library and can be called directly or in their respective submodules. A typical workflow might look like the following: \n",
    "\n",
    "- Load your dataset into a format which can be directly indexed (numpy array or pointer to a file on disk)\n",
    "- Preprocess the raw data (wavelet transformation)\n",
    "- Preprocess your outputs (the variable you want to decode)\n",
    "- Define appropriate loss functions for your output and train the model \n",
    "- Predict performance across all cross validated models\n",
    "- Visualize influence of different input frequencies on model output\n",
    "\n",
    "We use the calcium dataset here as it has lower sampling rate and is therefore faster to preprocess and train, which makes it suitable to also run the preprocessing in a Colab notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9iwZvplEoO70",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "---\n",
    "## **Install and import DeepInsight**\n",
    "---\n",
    "Make sure you are using a **GPU runtime** if you want to train your own models. Go to Runtime -> Change Runtime type to change from CPU to GPU.\n",
    "You can check the GPU which is used in Colab by running !nvidia-smi in a new cell "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Uguw1SjlZLRX",
    "outputId": "fa22ce71-f3ff-4ff7-ac55-491d7011f2e0",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Import DeepInsight\n",
    "import sys\n",
    "sys.path.insert(0, \"/home/marx/Documents/Github/DeepInsight\")\n",
    "import deepinsight\n",
    "\n",
    "# Other imports\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import plotly.graph_objs as go\n",
    "from skimage import io\n",
    "\n",
    "# Initialize plotly figures\n",
    "from plotly.offline import init_notebook_mode \n",
    "init_notebook_mode(connected = True)\n",
    "\n",
    "# Make sure the output width is adjusted for better export as HTML\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:70% !important; }</style>\"))\n",
    "display(HTML(\"<style>.output_result { max-width:70% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "INZc18eRZTYL",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "## **Load and preprocess your data**\n",
    "---\n",
    "For this example we provide two-photon calcium imaging data from a mouse in a virtual environment. Calcium traces together with the variable of interest is stored in one .mat file. You can load it from whatever datasource you want, just make sure that the dimensions match. \n",
    "\n",
    "The input to the model in the form of (Timepoints x Number of Cells) is stored in `raw_data`\n",
    "\n",
    "The output to be decoded is in the form of (Timepoints x 1) and is stored in `output` together with timestamps for the output in `raw_timestamps`\n",
    "\n",
    "---\n",
    "\n",
    "**Run the next cells if you want to load the example data and preprocess it. You can also skip to 'Preprocess Data' to just load the preprocessed file and directly train the model.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "Q1GNMR41iqBf",
    "outputId": "42008674-03b7-4837-dbe8-372a89a36e03",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "base_path = './example_data/calcium/'\n",
    "fp_raw_file = base_path + 'traces_M1336.mat'\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)\n",
    "if not os.path.exists(fp_raw_file): # Careful as next command is a colab command where parameters had to be hard coded. Keep in mind if changing fp_raw_file\n",
    "    !wget https://ndownloader.figshare.com/files/24024683 -O ./example_data/calcium/traces_M1336.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uCT9WQ56wTia",
    "outputId": "3a530bab-7aee-4675-b062-ba656c7f2c8b",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Set base variables\n",
    "sampling_rate = 30 # Might also be stored in above mat file for easier access\n",
    "channels = np.arange(0, 100) # For this recording channels corresponds to cells. We only use the first 100 cells to speed up preprocessing (Change this if you run it on your own dataset)\n",
    "\n",
    "# Also define Paths to access downloaded files\n",
    "base_path = './example_data/calcium/'\n",
    "fp_raw_file = base_path + 'traces_M1336.mat' # This is an example dataset containing calcium traces and linear position in a virtual track\n",
    "fp_deepinsight = base_path + 'processed_M1336.h5' # This will be the processed HDF5 file\n",
    "\n",
    "# Load data from mat file\n",
    "calcium_data = loadmat(fp_raw_file)['dataSave']\n",
    "raw_data = np.squeeze(calcium_data['df_f'][0][0])\n",
    "raw_timestamps = np.arange(0, raw_data.shape[0]) / sampling_rate\n",
    "output = np.squeeze(calcium_data['pos_dat'][0][0])\n",
    "\n",
    "print('Data loaded. Calcium traces: {}, Decoding target {}'.format(raw_data.shape, output.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fNbPYTuf79de",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "### Plot example calcium traces\n",
    "---\n",
    "To give a visual impression of the input to our model we can now plot calcium traces for a bunch of different cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "colab_type": "code",
    "id": "s7LG4uj8ywFw",
    "outputId": "05677e37-cfd3-4ea9-ff8a-f6c1107f5330",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "end_point, y_offset, num_cells = 10000, 400, 6\n",
    "fig = go.Figure()\n",
    "for i in range(0, num_cells):\n",
    "    fig.add_trace(go.Scatter(x=np.arange(0, end_point) / sampling_rate, y=raw_data[0:end_point, i] + (i * y_offset), line=dict(color='rgba(0, 0, 0, 0.85)', width=2), name='Cell {}'.format(i+1)))\n",
    "# aesthetics\n",
    "fig.update_yaxes(visible=False)\n",
    "fig.update_layout(showlegend=False,plot_bgcolor=\"white\",width=1800, height=650,margin=dict(t=20,l=20,b=20,r=20),xaxis_title='Time (s)', font=dict(family='Open Sans', size=16, color='black'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ubJSXsC_yh9",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "### Preprocess data \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "O61lbp1TZTYM",
    "outputId": "6aad0856-0424-4954-e985-1c3f8f672ff7",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(fp_deepinsight):\n",
    "    if os.path.exists(fp_raw_file): # Only do this if user downloaded raw files otherwise download preprocessed hdf5 file\n",
    "        # Process output for use as decoding target\n",
    "        # As the mouse is running on a virtual linear track we have a circular variable. We can solve this by either:\n",
    "        # (1) Using a circular loss function or \n",
    "        # (2) Using the sin and cos of the variable\n",
    "        # For this dataset we choose method (2), see the loss calculation for head directionality on CA1 recordings for an example of (1)\n",
    "        output = (output - np.nanmin(output)) / (np.nanmax(output) - np.nanmin(output))\n",
    "        output = (output * 2*np.pi) - np.pi # Scaled to -pi / pi\n",
    "        output = np.squeeze(np.column_stack([np.sin(output), np.cos(output)]))\n",
    "        output = pd.DataFrame(output).ffill().bfill().values # Get rid of NaNs\n",
    "        output_timestamps = raw_timestamps # In this recording timestamps are the same for output and raw_data, meaning they are already aligned to each other\n",
    "\n",
    "        # Transform raw data to frequency domain\n",
    "        # We use a small cutoff (1/500) for the low frequencies to keep the dimensions low & the model training fast\n",
    "        deepinsight.preprocess.preprocess_input(fp_deepinsight, raw_data, sampling_rate=sampling_rate, average_window=1, wave_highpass=1/500, wave_lowpass=sampling_rate, channels=channels) \n",
    "        # # Prepare outputs\n",
    "        deepinsight.preprocess.preprocess_output(fp_deepinsight, raw_timestamps, output, output_timestamps, average_window=1, dataset_name='sin_cos')\n",
    "    else:\n",
    "        if not os.path.exists(base_path):\n",
    "            os.makedirs(base_path)\n",
    "        if not os.path.exists(fp_deepinsight):\n",
    "            !wget https://ndownloader.figshare.com/files/23658674 -O ./example_data/calcium/processed_M1336.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PEjBzYQYo9d9",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "### Plot preprocessed data\n",
    "---\n",
    "We plot examples to double check the wavelet preprocessing. Each plot shows the wavelet processed calcium traces for one cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xeS4h0_5k54q",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "hdf5_file = h5py.File(fp_deepinsight, mode='r')\n",
    "wavelets = hdf5_file['inputs/wavelets']\n",
    "frequencies = np.round(hdf5_file['inputs/fourier_frequencies'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "colab_type": "code",
    "id": "3Isfo5s5CIhO",
    "outputId": "122a960f-05fa-4831-f442-c65daf4a92f3",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "num_cells, gap = 20, 30\n",
    "fig = go.Figure()\n",
    "for i in range(0, num_cells):\n",
    "    this_z = wavelets[0:wavelets.shape[0]//2:gap,:,i].transpose()\n",
    "    fig.add_heatmap(x=np.arange(0, this_z.shape[0]) / (sampling_rate / gap), z=this_z,colorscale='Viridis',visible=False,showscale=False)\n",
    "fig.data[0].visible = True\n",
    "# aesthetics\n",
    "steps = []\n",
    "for i in range(len(fig.data)):\n",
    "    step = dict(method=\"update\",label=\"Cell {}\".format(i+1),args=[{\"visible\": [False] * len(fig.data)}])\n",
    "    step[\"args\"][0][\"visible\"][i] = True  # Toggle i'th trace to \"visible\"\n",
    "    steps.append(step)\n",
    "sliders = [dict(active=10,currentvalue={\"prefix\": \"Cell: \", \"visible\" : False},pad={\"t\": 70},steps=steps)]\n",
    "\n",
    "fig.update_layout(width=1800, height=650,sliders=sliders, yaxis = dict(tickvals=np.arange(0, len(frequencies)), ticktext = ['{:.3f}'.format(i) for i in frequencies], autorange='reversed'), yaxis_title='Frequency (Hz)',\n",
    "                  showlegend=False, plot_bgcolor=\"white\",margin=dict(t=20,l=20,b=20,r=20),xaxis_title='Time (s)', font=dict(family='Open Sans', size=16, color='black'))\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yIXVttGdEmzd",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R2hXQTtuZTYX",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "## **Train the model**\n",
    "---\n",
    "The following command uses 5 cross validations to train the models and stores weights in HDF5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "z3wSllkHZTYY",
    "outputId": "c6715e26-35b4-40bf-9623-1628a02600ae",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Define loss functions and train model, if more then one behaviour/stimuli needs to be decoded, define loss functions and weights for each of them here\n",
    "loss_functions = {'sin_cos' : 'mse'}\n",
    "loss_weights = {'sin_cos' : 1} \n",
    "user_opts = {'epochs' : 10, 'sample_per_epoch' : 250} # Speed up for Colab, normally set to {'epochs' : 20, 'sample_per_epoch' : 250\n",
    "deepinsight.train.run_from_path(fp_deepinsight, loss_functions, loss_weights, user_opts=user_opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p6ybugPYcuRe",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "## **Evaluate model performance**\n",
    "---\n",
    "Here we calculate the losses over the whole duration of the experiment. Step size indicates how many timesteps are skipped between samples. Note that each sample contains 64 timesteps, so setting step size to 64 will result in non-overlapping samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "ZBrHYchnVVck",
    "outputId": "d310f7e3-e760-4382-87cc-4965aea6dbcc",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "step_size = 100\n",
    "\n",
    "# Get loss and shuffled loss for influence plot, both is also stored back to HDF5 file\n",
    "losses, output_predictions, indices = deepinsight.analyse.get_model_loss(fp_deepinsight, stepsize=step_size)\n",
    "\n",
    "# Get real output from HDF5 file\n",
    "hdf5_file = h5py.File(fp_deepinsight, mode='r')\n",
    "output_real = hdf5_file['outputs/sin_cos'][indices,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2WUiAPxPdw6c",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "### Visualize model performance\n",
    "---\n",
    "We plot the real output vs. the predicted output for the above trained models. The real output is linearized as in the virtual reality environment the start follows after the mouse reaches the end, therefore we can use a circular variable. Also note that the example plot below is only trained on a subset of channels (see channels variable, default=100) and a limited number of epochs (see epochs, default=5), to make training in the Colab notebook faster. The performance on the fully evaluated dataset is higher. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "colab_type": "code",
    "id": "TrimxQpIX20O",
    "outputId": "c831ca7a-aa76-47b0-ed45-80fb788b8c40",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=np.arange(0, output_real.shape[0]) / (sampling_rate / step_size), y=output_real[:,0], line=dict(color='rgba(0, 0, 0, 0.85)', width=2), name='Real'))\n",
    "fig.add_trace(go.Scatter(x=np.arange(0, output_real.shape[0]) / (sampling_rate / step_size), y=output_predictions['sin_cos'][:,0], line=dict(color='rgb(67, 116, 144)', width=3), name='Predicted'))\n",
    "\n",
    "# aesthetics\n",
    "#fig.update_yaxes(visible=False)\n",
    "fig.update_layout(width=1800, height=650, plot_bgcolor=\"rgb(245, 245, 245)\",margin=dict(t=20,l=20,b=20,r=20),xaxis_title='Time (s)', yaxis_title='Decoding target (sin)', font=dict(family='Open Sans', size=16, color='black'))\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jPkRVpHPX25i",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "inqoPEb4eCmu",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---\n",
    "### Get shuffled model performance\n",
    "---\n",
    "We use the shuffled loss to evaluate feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "LM9SKb4FZTYc",
    "outputId": "066e9263-c598-428f-f811-3e9169ce9c6e",
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "shuffled_losses_ax1 = deepinsight.analyse.get_shuffled_model_loss(fp_deepinsight, axis=1, stepsize=step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dCVfQGTxpm05",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate residuals, make sure there is no division by zero by adding small constant.\n",
    "residuals = (shuffled_losses_ax1 - losses) / (losses + 0.1)\n",
    "residuals_mean = np.mean(residuals, axis=1)[:,0]\n",
    "residuals_standarderror = np.std(residuals, axis=1)[:,0] / np.sqrt(residuals.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1bSLxr8RJvnN",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "### Show feature importance for frequency axis\n",
    "---\n",
    "This plot shows the relative influence of each frequency band on the decoding of the position in the virtual environment. We plot the mean across samples + the standard error for each frequency band. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "colab_type": "code",
    "id": "BCeTJQykprE7",
    "outputId": "cd340d3f-82d8-49b1-d77d-ec2bc2b93683",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "end_point, y_offset, num_cells = 1000, 400, 6\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=np.arange(0, residuals_mean.shape[0]), y=residuals_mean, line=dict(color='rgba(0, 0, 0, 0.85)', width=3), name='Real',\n",
    "                         error_y=dict(type='data', array=residuals_standarderror, visible=True, color='rgb(67, 116, 144)', thickness=3)))\n",
    "\n",
    "# aesthetics\n",
    "#fig.update_yaxes(visible=False)\n",
    "fig.update_layout(width=1800, height=650, plot_bgcolor=\"rgb(245, 245, 245)\",margin=dict(t=20,l=20,b=20,r=20), xaxis = dict(tickvals=np.arange(0, len(frequencies)), ticktext = ['{:.3f}'.format(i) for i in frequencies], autorange='reversed'),\n",
    "                  xaxis_title='Frequency (Hz)', yaxis_title='Relative influence', font=dict(family='Open Sans', size=16, color='black',\n",
    "))\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xW1fimfsJ2Hl",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "### Show feature importance for cell axis\n",
    "---\n",
    "For this we shuffle across the cell dimension to see the influence each cell has on the decoding of position and then plot it back to the calcium ROIs. In the plot below the size of the dot is indicating the relative influence of this ROI (cell) on the decoding performance. Red dots indicate a high influence of this cell on the decoding of position and blue dots indicate a negative influence of this cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "34Cnoa_fpq9z",
    "outputId": "3989f4dc-20d7-4261-fcc1-fee2084058f2",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "shuffled_losses = deepinsight.analyse.get_shuffled_model_loss(fp_deepinsight, axis=2, stepsize=step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bh0ZvGpEKE4r",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate residuals, make sure there is no division by zero by adding small constant.\n",
    "residuals = (shuffled_losses - losses) / (losses + 0.1)\n",
    "residuals_mean = np.mean(residuals, axis=1)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 785
    },
    "colab_type": "code",
    "id": "AYtjoLGaF9Ml",
    "outputId": "1dab7de7-43dd-46f3-f6ae-b06600045e42",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Get some files for plotting the importance of each cell back to brain anatomy\n",
    "if not os.path.exists('./example_data/calcium/centroid_YX.mat'):\n",
    "    !wget https://www.dropbox.com/s/z8ynet2nkt9pe1u/centroid_YX.mat -O ./example_data/calcium/centroid_YX.mat\n",
    "if not os.path.exists('./example_data/calcium/calcium_rois.jpg'): \n",
    "    !wget https://www.dropbox.com/s/czak7rphajslcr0/test_rois_F5.jpg -O ./example_data/calcium/calcium_rois.jpg\n",
    "roi_data = loadmat('./example_data/calcium/centroid_YX.mat')['xy_coords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "colab_type": "code",
    "id": "nMYWGuPb6AWK",
    "outputId": "a1e353e7-ad0b-4a9e-ffda-23bb74a952fb",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "point_size_adjustment = 1250\n",
    "all_pos = residuals_mean > 0\n",
    "all_pos_channels = channels[all_pos]\n",
    "all_neg_channels = channels[~all_pos]\n",
    "fig.add_trace(go.Image(z=io.imread('./example_data/calcium/calcium_rois.jpg')))\n",
    "fig.add_trace(go.Scatter(x=roi_data[:,1], y=roi_data[:,0], marker_symbol='circle', mode='markers', marker=dict(color='white', opacity=0.5, line=dict(color='white',width=0)), name='Cell centers'))\n",
    "fig.add_trace(go.Scatter(x=roi_data[all_pos_channels,1], y=roi_data[all_pos_channels,0], marker_symbol='circle', mode='markers', marker=dict(color='red', size=residuals_mean[all_pos]*point_size_adjustment, opacity=0.5, line=dict(color='black',width=3)), name='Pos. influence'))\n",
    "fig.add_trace(go.Scatter(x=roi_data[all_neg_channels,1], y=roi_data[all_neg_channels,0], marker_symbol='circle', mode='markers', marker=dict(color='blue', size=residuals_mean[~all_pos]*-point_size_adjustment, opacity=0.5, line=dict(color='black',width=3)), name='Neg. influence'))\n",
    "\n",
    "fig.update_layout(width=1800, height=650, showlegend=False, plot_bgcolor=\"white\",margin=dict(t=10,l=0,b=10,r=0), xaxis=dict(showticklabels=False), yaxis=dict(showticklabels=False))\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xR73Csfr-U83",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "deepinsight_calcium_example.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bit5fa017aec819437bacf63081b14c694c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
