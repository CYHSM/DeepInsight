{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# Introduction to DeepInsight - Decoding position, speed and head direction from tetrode CA1 recordings\n",
    "\n",
    "This notebook stands as an example of how to use DeepInsight v0.5 on tetrode data and can be used as a guide on how to adapt it to your own datasets. All methods are stored in the deepinsight library and can be called directly or in their respective submodules. A typical workflow might look like the following: \n",
    "- Load your dataset into a format which can be directly indexed (numpy array or pointer to a file on disk)\n",
    "- Preprocess the raw data (wavelet transformation)\n",
    "- Preprocess your outputs (the variable you want to decode)\n",
    "- Define appropriate loss functions for your output and train the model \n",
    "- Predict performance across all cross validated models\n",
    "- Visualize influence of different input frequencies on model output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DeepInsight\n",
    "import sys\n",
    "sys.path.insert(0, \"/home/marx/Documents/Github/DeepInsight\")\n",
    "import deepinsight\n",
    "# Choose GPU\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "# Additional imports\n",
    "from scipy.io import loadmat\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---\n",
    "---\n",
    "Here you can define the paths to your raw data files, and create file names for the preprocessed HDF5 datasets.\n",
    "\n",
    "The data we use here is usually relatively large in its raw format. Running it through the next lines takes roughly 24 hours for a 40 minute recording.\n",
    "\n",
    "We provide a preprocess file to play with the code. See next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Starting wavelet transformation (n=73073, chunks=685, frequencies=26)\n"
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-07dc520d6bee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Transform raw data to frequency domain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mdeepinsight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_deepinsight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampling_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage_window\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwave_highpass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwave_lowpass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampling_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;31m# # Prepare outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# deepinsight.util.tetrode.preprocess_output(fp_deepinsight, raw_timestamps, output,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Github/DeepInsight/deepinsight/preprocess.py\u001b[0m in \u001b[0;36mpreprocess_input\u001b[0;34m(fp_hdf_out, raw_data, average_window, channels, window_size, gap_size, sampling_rate, scaling_factor, num_cores, **args)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfull_transform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             (wavelet_power, wavelet_frequencies, _) = wt.wavelet_transform(raw_chunk,\n\u001b[0;32m---> 86\u001b[0;31m                                                                            sampling_rate=sampling_rate, scaling_factor=scaling_factor, average_window=average_window, **args)\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mwavelet_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_chunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0maverage_window\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_fourier_frequencies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_chunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "# Define base paths\n",
    "base_path = './example_data/calcium/'\n",
    "fp_raw_file = base_path + 'traces_M1336.mat' # This is an example dataset containing calcium traces and linear position in a virtual track\n",
    "fp_deepinsight = base_path + 'processed_M1336.h5' # This will be the processed HDF5 file\n",
    "sampling_rate = 30 # Might also be stored in above mat file for easier access\n",
    "\n",
    "if os.path.exists(fp_raw_file):\n",
    "    # Load data \n",
    "    calcium_data = loadmat(fp_raw_file)['dataSave']\n",
    "    raw_data = np.squeeze(calcium_data['df_f'][0][0])\n",
    "    raw_timestamps = np.arange(0, raw_data.shape[0]) / sampling_rate\n",
    "    output = np.squeeze(calcium_data['pos_dat'][0][0])\n",
    "    output_timestamps = raw_timestamps # In this recording timestamps are the same for output and raw_data\n",
    "        \n",
    "    # Transform raw data to frequency domain\n",
    "    deepinsight.preprocess.preprocess_input(fp_deepinsight, raw_data, sampling_rate=sampling_rate, average_window=1, wave_highpass=1/500, wave_lowpass=sampling_rate)\n",
    "    # # Prepare outputs\n",
    "    # deepinsight.util.tetrode.preprocess_output(fp_deepinsight, raw_timestamps, output,\n",
    "    #                                            output_timestamps, sampling_rate=info['sampling_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepinsight.util.wavelet_transform as wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(_, wavelet_frequencies) = wt.wavelet_transform(np.ones(50000), sampling_rate, average_window=1, scaling_factor=0.5, wave_highpass=1/500, wave_lowpass=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelet_frequencies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/500"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---\n",
    "---\n",
    "The above steps create a HDF5 file with all important data for training the model.\n",
    "\n",
    "You can download the preprocessed dataset by running the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://ndownloader.figshare.com/files/20150468 -O ./example_data/processed_R2478.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---\n",
    "---\n",
    "Now we can train the model. \n",
    "\n",
    "The following command uses 5 cross validations to train the models and stores weights in HDF5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss functions and train model\n",
    "loss_functions = {'position' : 'euclidean_loss', \n",
    "                  'head_direction' : 'cyclical_mae_rad', \n",
    "                  'speed' : 'mae'}\n",
    "loss_weights = {'position' : 1, \n",
    "                'head_direction' : 25, \n",
    "                'speed' : 2}\n",
    "deepinsight.train.run_from_path(fp_deepinsight, loss_functions, loss_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get loss and shuffled loss for influence plot, both is also stored back to HDF5 file\n",
    "losses, output_predictions, indices = deepinsight.analyse.get_model_loss(fp_deepinsight,\n",
    "                                                                         stepsize=10)\n",
    "shuffled_losses = deepinsight.analyse.get_shuffled_model_loss(fp_deepinsight, axis=1,\n",
    "                                                              stepsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---\n",
    "---\n",
    "Above line calculates the loss and shuffled loss across the full experiment and writes it back to the HDF5 file.\n",
    "\n",
    "Below command visualizes the influence across different frequency bands for all samples\n",
    "\n",
    "Note that Figure 3 in the manuscript shows influence across animals, while this plot shows the influence for one animal across the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot influence across behaviours\n",
    "deepinsight.visualize.plot_residuals(fp_deepinsight, frequency_spacing=2,\n",
    "                                     output_names=['Position', 'Head Direction', 'Speed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bit5fa017aec819437bacf63081b14c694c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}